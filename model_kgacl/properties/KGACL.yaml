kg_embedding_size: 64
layers: [64]
mess_dropout: 0.5
reg_weight: 1e-5
aggregator_type: 'bi'

# dataset config
field_separator: "\t"
seq_separator: " "
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
RATING_FIELD: rating
HEAD_ENTITY_ID_FIELD: head_id
TAIL_ENTITY_ID_FIELD: tail_id
RELATION_ID_FIELD: relation_id
ENTITY_ID_FIELD: entity_id
NEG_PREFIX: neg_
LABEL_FIELD: label
load_col:
    inter: [user_id, item_id, rating]
    kg: [head_id, relation_id, tail_id]
    link: [item_id, entity_id]
val_interval:
    rating: "[3,inf)"
# training and evaluation
epochs: 200
train_batch_size: 2048           #4096
eval_batch_size:  4096          #102400
valid_metric: MRR@10
stopping_step: 100
# model
embedding_size: 64
train_neg_sample_args: {'distribution': 'uniform'}
n_layers: 2
mlp_hidden_size: [64, 64, 64]
loss_function: 'inner_product'
margin: 1.0
drop_ratio: 0.5
